{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ad350ac0",
      "metadata": {
        "id": "ad350ac0"
      },
      "source": [
        "## Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "833688bb",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "833688bb"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "æ•°æ®å‡†å¤‡è„šæœ¬\n",
        "åŠŸèƒ½ï¼š\n",
        "1. ä»YOLOæ ¼å¼æ•°æ®é›†è¯»å–å¹¶åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†\n",
        "2. ä¸ºç›®æ ‡æ£€æµ‹å‡†å¤‡æ•°æ®ï¼ˆæ‰€æœ‰ç±»åˆ«ç»Ÿä¸€ä¸º\"fly\"ï¼‰\n",
        "3. ä¸ºåˆ†ç±»å‡†å¤‡è£å‰ªåçš„å›¾åƒæ•°æ®é›†ï¼ˆLong/Short/Ambiguousï¼‰\n",
        "\"\"\"\n",
        "\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "import random\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "class DataPreparation:\n",
        "    def __init__(self, yolo_data_root, output_root, train_ratio=0.8, exclude_ambiguous=True):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            yolo_data_root: YOLOæ ¼å¼æ•°æ®æ ¹ç›®å½•ï¼ˆåŒ…å«images/å’Œlabels/å­ç›®å½•ï¼‰\n",
        "            output_root: è¾“å‡ºç›®å½•\n",
        "            train_ratio: è®­ç»ƒé›†æ¯”ä¾‹\n",
        "            exclude_ambiguous: æ˜¯å¦æ’é™¤Ambiguousç±»åˆ«\n",
        "        \"\"\"\n",
        "        self.yolo_data_root = Path(yolo_data_root)\n",
        "        self.images_dir = self.yolo_data_root / 'images'\n",
        "        self.labels_dir = self.yolo_data_root / 'labels'\n",
        "        self.classes_file = self.yolo_data_root / 'classes.txt'\n",
        "        self.output_root = Path(output_root)\n",
        "        self.train_ratio = train_ratio\n",
        "        self.exclude_ambiguous = exclude_ambiguous\n",
        "\n",
        "        # è¯»å–ç±»åˆ«\n",
        "        with open(self.classes_file, 'r', encoding='utf-8') as f:\n",
        "            self.classes = [line.strip() for line in f if line.strip()]\n",
        "\n",
        "        print(f\"ç±»åˆ«: {self.classes}\")\n",
        "\n",
        "        # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶\n",
        "        self.image_files = sorted(list(self.images_dir.glob('*.jpg')) + list(self.images_dir.glob('*.png')))\n",
        "\n",
        "        # è¿‡æ»¤å‡ºæœ‰å¯¹åº”æ ‡æ³¨æ–‡ä»¶çš„å›¾åƒ\n",
        "        self.valid_images = []\n",
        "        for img_path in self.image_files:\n",
        "            label_path = self.labels_dir / (img_path.stem + '.txt')\n",
        "            if label_path.exists():\n",
        "                self.valid_images.append(img_path)\n",
        "\n",
        "        print(f\"åŠ è½½æ•°æ®é›†: {len(self.valid_images)} å¼ æœ‰æ•ˆå›¾ç‰‡ï¼ˆå…± {len(self.image_files)} å¼ ï¼‰\")\n",
        "\n",
        "    def parse_yolo_label(self, label_path, img_width, img_height):\n",
        "        \"\"\"è§£æYOLOæ ¼å¼æ ‡æ³¨æ–‡ä»¶\n",
        "\n",
        "        Args:\n",
        "            label_path: æ ‡æ³¨æ–‡ä»¶è·¯å¾„\n",
        "            img_width: å›¾åƒå®½åº¦\n",
        "            img_height: å›¾åƒé«˜åº¦\n",
        "\n",
        "        Returns:\n",
        "            boxes: [(class_id, x1, y1, x2, y2), ...]\n",
        "        \"\"\"\n",
        "        boxes = []\n",
        "\n",
        "        if not label_path.exists():\n",
        "            return boxes\n",
        "\n",
        "        with open(label_path, 'r') as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) < 5:\n",
        "                    continue\n",
        "\n",
        "                class_id = int(parts[0])\n",
        "                x_center = float(parts[1])\n",
        "                y_center = float(parts[2])\n",
        "                width = float(parts[3])\n",
        "                height = float(parts[4])\n",
        "\n",
        "                # è½¬æ¢ä¸ºç»å¯¹åæ ‡\n",
        "                x1 = (x_center - width / 2) * img_width\n",
        "                y1 = (y_center - height / 2) * img_height\n",
        "                x2 = (x_center + width / 2) * img_width\n",
        "                y2 = (y_center + height / 2) * img_height\n",
        "\n",
        "                boxes.append((class_id, x1, y1, x2, y2))\n",
        "\n",
        "        return boxes\n",
        "\n",
        "    def prepare_detection_data(self):\n",
        "        \"\"\"å‡†å¤‡ç›®æ ‡æ£€æµ‹æ•°æ®ï¼ˆYOLOæ ¼å¼ï¼Œæ‰€æœ‰ç±»åˆ«ç»Ÿä¸€ä¸ºflyï¼‰\"\"\"\n",
        "        print(\"\\n=== å‡†å¤‡ç›®æ ‡æ£€æµ‹æ•°æ® ===\")\n",
        "\n",
        "        # åˆ›å»ºè¾“å‡ºç›®å½•\n",
        "        detection_root = self.output_root / \"detection\"\n",
        "        for split in ['train', 'val']:\n",
        "            (detection_root / split / 'images').mkdir(parents=True, exist_ok=True)\n",
        "            (detection_root / split / 'labels').mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†\n",
        "        images = self.valid_images.copy()\n",
        "        random.shuffle(images)\n",
        "        train_size = int(len(images) * self.train_ratio)\n",
        "        train_images = images[:train_size]\n",
        "        val_images = images[train_size:]\n",
        "\n",
        "        print(f\"è®­ç»ƒé›†: {len(train_images)} å¼ , éªŒè¯é›†: {len(val_images)} å¼ \")\n",
        "\n",
        "        # å¤„ç†è®­ç»ƒé›†å’ŒéªŒè¯é›†\n",
        "        for split, img_list in [('train', train_images), ('val', val_images)]:\n",
        "            print(f\"\\nå¤„ç†{split}é›†...\")\n",
        "            for img_path in tqdm(img_list):\n",
        "                # å¤åˆ¶å›¾ç‰‡\n",
        "                output_img_path = detection_root / split / 'images' / img_path.name\n",
        "                shutil.copy(img_path, output_img_path)\n",
        "\n",
        "                # è¯»å–å¹¶è½¬æ¢æ ‡æ³¨ï¼ˆæ‰€æœ‰ç±»åˆ«ç»Ÿä¸€ä¸º0ï¼‰\n",
        "                label_path = self.labels_dir / (img_path.stem + '.txt')\n",
        "                output_label_path = detection_root / split / 'labels' / (img_path.stem + '.txt')\n",
        "\n",
        "                with open(label_path, 'r') as f_in, open(output_label_path, 'w') as f_out:\n",
        "                    for line in f_in:\n",
        "                        parts = line.strip().split()\n",
        "                        if len(parts) >= 5:\n",
        "                            # å°†æ‰€æœ‰ç±»åˆ«æ”¹ä¸º0ï¼ˆç»Ÿä¸€ä¸ºflyï¼‰\n",
        "                            f_out.write(f\"0 {' '.join(parts[1:])}\\n\")\n",
        "\n",
        "        # ç”Ÿæˆdata.yamlé…ç½®æ–‡ä»¶\n",
        "        yaml_content = f\"\"\"path: {detection_root.absolute()}\n",
        "train: train/images\n",
        "val: val/images\n",
        "\n",
        "nc: 1\n",
        "names: ['fly']\n",
        "\"\"\"\n",
        "        with open(detection_root / 'data.yaml', 'w') as f:\n",
        "            f.write(yaml_content)\n",
        "\n",
        "        print(f\"\\nâœ… ç›®æ ‡æ£€æµ‹æ•°æ®å‡†å¤‡å®Œæˆï¼ä¿å­˜åœ¨: {detection_root}\")\n",
        "        return detection_root / 'data.yaml'\n",
        "\n",
        "    def prepare_classification_data(self):\n",
        "        \"\"\"å‡†å¤‡åˆ†ç±»æ•°æ®ï¼ˆè£å‰ªåçš„å›¾åƒï¼ŒæŒ‰ç±»åˆ«åˆ†ç±»ï¼‰\"\"\"\n",
        "        print(\"\\n=== å‡†å¤‡åˆ†ç±»æ•°æ® ===\")\n",
        "\n",
        "        # åˆ›å»ºè¾“å‡ºç›®å½•\n",
        "        classification_root = self.output_root / \"classification\"\n",
        "\n",
        "        # ç¡®å®šè¦å¤„ç†çš„ç±»åˆ«\n",
        "        if self.exclude_ambiguous:\n",
        "            target_classes = [c for c in self.classes if c != 'Ambiguous']\n",
        "        else:\n",
        "            target_classes = self.classes\n",
        "\n",
        "        print(f\"å¤„ç†ç±»åˆ«: {target_classes}\")\n",
        "\n",
        "        for split in ['train', 'val']:\n",
        "            for category in target_classes:\n",
        "                (classification_root / split / category).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼ˆä½¿ç”¨ç›¸åŒçš„åˆ’åˆ†ï¼‰\n",
        "        images = self.valid_images.copy()\n",
        "        random.shuffle(images)\n",
        "        train_size = int(len(images) * self.train_ratio)\n",
        "        train_images = set(images[:train_size])\n",
        "\n",
        "        # å¤„ç†æ‰€æœ‰å›¾åƒ\n",
        "        print(\"è£å‰ªå¹¶ä¿å­˜å›¾åƒ...\")\n",
        "        crop_counts = {'train': {}, 'val': {}}\n",
        "\n",
        "        for img_path in tqdm(self.valid_images):\n",
        "            # ç¡®å®šæ˜¯è®­ç»ƒé›†è¿˜æ˜¯éªŒè¯é›†\n",
        "            split = 'train' if img_path in train_images else 'val'\n",
        "\n",
        "            # è¯»å–å›¾åƒ\n",
        "            try:\n",
        "                img = Image.open(img_path).convert('RGB')\n",
        "            except Exception as e:\n",
        "                print(f\"æ— æ³•æ‰“å¼€å›¾åƒ {img_path}: {e}\")\n",
        "                continue\n",
        "\n",
        "            # è¯»å–æ ‡æ³¨\n",
        "            label_path = self.labels_dir / (img_path.stem + '.txt')\n",
        "            boxes = self.parse_yolo_label(label_path, img.width, img.height)\n",
        "\n",
        "            # è£å‰ªæ¯ä¸ªæ ‡æ³¨æ¡†\n",
        "            for idx, (class_id, x1, y1, x2, y2) in enumerate(boxes):\n",
        "                category_name = self.classes[class_id]\n",
        "\n",
        "                # å¦‚æœæ’é™¤Ambiguousç±»åˆ«\n",
        "                if self.exclude_ambiguous and category_name == 'Ambiguous':\n",
        "                    continue\n",
        "\n",
        "                # ç¡®ä¿è¾¹ç•Œåœ¨å›¾åƒå†…\n",
        "                x1 = max(0, int(x1))\n",
        "                y1 = max(0, int(y1))\n",
        "                x2 = min(img.width, int(x2))\n",
        "                y2 = min(img.height, int(y2))\n",
        "\n",
        "                if x2 <= x1 or y2 <= y1:\n",
        "                    continue\n",
        "\n",
        "                # è£å‰ª\n",
        "                cropped = img.crop((x1, y1, x2, y2))\n",
        "\n",
        "                # ä¿å­˜\n",
        "                if category_name not in crop_counts[split]:\n",
        "                    crop_counts[split][category_name] = 0\n",
        "                crop_counts[split][category_name] += 1\n",
        "\n",
        "                crop_filename = f\"{img_path.stem}_{idx}_{category_name}.jpg\"\n",
        "                output_path = classification_root / split / category_name / crop_filename\n",
        "                cropped.save(output_path, quality=95)\n",
        "\n",
        "        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯\n",
        "        print(f\"\\nâœ… åˆ†ç±»æ•°æ®å‡†å¤‡å®Œæˆï¼ä¿å­˜åœ¨: {classification_root}\")\n",
        "        print(\"\\næ•°æ®é›†ç»Ÿè®¡:\")\n",
        "        for split in ['train', 'val']:\n",
        "            print(f\"\\n{split}é›†:\")\n",
        "            total = sum(crop_counts[split].values())\n",
        "            for category, count in sorted(crop_counts[split].items()):\n",
        "                percentage = 100 * count / total if total > 0 else 0\n",
        "                print(f\"  {category}: {count} ({percentage:.1f}%)\")\n",
        "\n",
        "        return classification_root\n",
        "\n",
        "\n",
        "def main():\n",
        "    # è®¾ç½®éšæœºç§å­\n",
        "    random.seed(42)\n",
        "\n",
        "    # é…ç½®è·¯å¾„\n",
        "    yolo_data_root = \"data_yolo\"  # YOLOæ ¼å¼æ•°æ®ç›®å½•\n",
        "    output_root = \"processed_data\"\n",
        "\n",
        "    # åˆ›å»ºæ•°æ®å‡†å¤‡å¯¹è±¡\n",
        "    data_prep = DataPreparation(\n",
        "        yolo_data_root=yolo_data_root,\n",
        "        output_root=output_root,\n",
        "        train_ratio=0.8,\n",
        "        exclude_ambiguous=True  # æ’é™¤Ambiguousç±»åˆ«\n",
        "    )\n",
        "\n",
        "    # å‡†å¤‡ç›®æ ‡æ£€æµ‹æ•°æ®\n",
        "    yaml_path = data_prep.prepare_detection_data()\n",
        "\n",
        "    # å‡†å¤‡åˆ†ç±»æ•°æ®\n",
        "    classification_root = data_prep.prepare_classification_data()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"âœ… æ•°æ®å‡†å¤‡å®Œæˆï¼\")\n",
        "    print(f\"æ£€æµ‹æ•°æ®é…ç½®: {yaml_path}\")\n",
        "    print(f\"åˆ†ç±»æ•°æ®ç›®å½•: {classification_root}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare files for Google Colab"
      ],
      "metadata": {
        "id": "tZXlU-fYWkyE"
      },
      "id": "tZXlU-fYWkyE"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzTBmEB1WiqB",
        "outputId": "2172202b-04a1-491f-c279-7ab4e203fae3"
      },
      "id": "AzTBmEB1WiqB",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "# è¯·å°†æ­¤è·¯å¾„æ›¿æ¢ä¸ºä½  Google Drive ä¸­ zip æ–‡ä»¶çš„å®é™…è·¯å¾„\n",
        "drive_zip_path = '/content/drive/MyDrive/genetics-project/processed_data.zip' # ä¾‹å¦‚: '/content/drive/MyDrive/data_yolo.zip'\n",
        "local_zip_path = Path('./dataset.zip')\n",
        "\n",
        "if Path(drive_zip_path).exists():\n",
        "    print(f\"æ­£åœ¨ä» Google Drive å¤åˆ¶ {drive_zip_path} åˆ°å½“å‰ç›®å½•...\")\n",
        "    shutil.copy(drive_zip_path, local_zip_path)\n",
        "    print(\"å¤åˆ¶å®Œæˆã€‚\")\n",
        "\n",
        "    if local_zip_path.exists():\n",
        "        print(f\"æ­£åœ¨è§£å‹ {local_zip_path}...\")\n",
        "        with zipfile.ZipFile(local_zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall('.')\n",
        "        print(\"è§£å‹å®Œæˆã€‚\")\n",
        "        # è§£å‹ååˆ é™¤ zip æ–‡ä»¶ä»¥èŠ‚çœç©ºé—´\n",
        "        local_zip_path.unlink()\n",
        "        print(f\"å·²åˆ é™¤ {local_zip_path}ã€‚\")\n",
        "    else:\n",
        "        print(f\"é”™è¯¯: æ— æ³•æ‰¾åˆ°å¤åˆ¶åçš„æ–‡ä»¶ {local_zip_path}ã€‚\")\n",
        "else:\n",
        "    print(f\"é”™è¯¯: æœªæ‰¾åˆ° Google Drive ä¸­çš„ zip æ–‡ä»¶: {drive_zip_path}ã€‚è¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®ã€‚\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ea6NRz8FX8S-",
        "outputId": "06b2930c-72b5-44ef-a659-824815fc9f46"
      },
      "id": "Ea6NRz8FX8S-",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "æ­£åœ¨ä» Google Drive å¤åˆ¶ /content/drive/MyDrive/genetics-project/processed_data.zip åˆ°å½“å‰ç›®å½•...\n",
            "å¤åˆ¶å®Œæˆã€‚\n",
            "æ­£åœ¨è§£å‹ dataset.zip...\n",
            "è§£å‹å®Œæˆã€‚\n",
            "å·²åˆ é™¤ dataset.zipã€‚\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68acf0ce",
      "metadata": {
        "id": "68acf0ce"
      },
      "source": [
        "## train_detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "456a5078",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "456a5078",
        "outputId": "651df026-6a08-4b0b-e0cf-cac0e87380b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== å¼€å§‹è®­ç»ƒæœè‡æ£€æµ‹æ¨¡å‹ ===\n",
            "æ¨¡å‹: yolov8n.pt\n",
            "æ•°æ®é…ç½®: datasets/detection/data.yaml\n",
            "è®­ç»ƒè½®æ•°: 100\n",
            "å›¾åƒå°ºå¯¸: 640\n",
            "æ‰¹æ¬¡å¤§å°: 16\n",
            "è®¾å¤‡: cuda\n",
            "WARNING âš ï¸ 'label_smoothing' is deprecated and will be removed in the future.\n",
            "Ultralytics 8.3.238 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=datasets/detection/data.yaml, degrees=10.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.5, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.1, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=fly_detector4, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/detect, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/detect/fly_detector4, save_frames=False, save_json=False, save_period=10, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 41.7MB/s 0.0s\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.4MB 156.6MB/s 0.0s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2647.0Â±1132.0 MB/s, size: 4043.7 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/detection/train/labels... 322 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 322/322 2.0Kit/s 0.2s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/detection/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2296.4Â±1627.4 MB/s, size: 4278.5 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/detection/val/labels... 81 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 81/81 1.9Kit/s 0.0s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/detection/val/labels.cache\n",
            "Plotting labels to /content/runs/detect/fly_detector4/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.01, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/detect/fly_detector4\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      1/100      2.14G       1.84      2.275      1.893         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 3.4s/it 1:11\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 1.3s/it 3.9s\n",
            "                   all         81        154    0.00387       0.61    0.00336   0.000995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      2/100      2.35G      1.846       1.79      1.936          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.0s/it 41.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 2.4it/s 1.3s\n",
            "                   all         81        154    0.00282     0.0649    0.00153   0.000295\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      3/100      2.36G      1.805      1.674      1.894          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.0s/it 43.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 2.1it/s 1.4s\n",
            "                   all         81        154    0.00367      0.188    0.00258   0.000665\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      4/100      2.38G      1.868      1.682      1.899          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.1s/it 45.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 2.7it/s 1.1s\n",
            "                   all         81        154      0.003      0.474    0.00243   0.000824\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      5/100      2.38G      1.804      1.589      1.836         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.1s/it 44.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.5it/s 0.9s\n",
            "                   all         81        154    0.00689      0.409    0.00497     0.0014\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      6/100      2.39G      1.797      1.546      1.872          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.0s/it 42.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 2.9it/s 1.0s\n",
            "                   all         81        154     0.0275      0.669     0.0291    0.00977\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      7/100      2.39G      1.763      1.451      1.809         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.1s/it 43.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 1.8it/s 1.6s\n",
            "                   all         81        154     0.0196      0.318     0.0151    0.00409\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      8/100      2.41G      1.738      1.466      1.825          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.1s/it 44.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.1it/s 1.0s\n",
            "                   all         81        154     0.0048      0.208    0.00291   0.000631\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      9/100      2.41G      1.725      1.378      1.787          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.0s/it 42.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.1it/s 1.0s\n",
            "                   all         81        154     0.0134      0.143    0.00656    0.00167\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     10/100      2.43G      1.667      1.328      1.722          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.0s/it 42.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.3it/s 0.9s\n",
            "                   all         81        154     0.0565      0.162     0.0495     0.0198\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     11/100      2.43G      1.647      1.301      1.716         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.0s/it 42.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.3it/s 0.9s\n",
            "                   all         81        154      0.299      0.468      0.268      0.108\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     12/100      2.43G      1.659      1.264      1.719          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.2s/it 46.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.1it/s 1.0s\n",
            "                   all         81        154      0.118      0.331     0.0868     0.0242\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     13/100      2.44G      1.673      1.279      1.716         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.1s/it 44.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 4.1it/s 0.7s\n",
            "                   all         81        154       0.23      0.377      0.205     0.0657\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     14/100      2.44G      1.632      1.284      1.715          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.0s/it 42.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.4it/s 0.9s\n",
            "                   all         81        154     0.0857     0.0325     0.0135    0.00421\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     15/100      2.45G      1.669      1.246      1.699         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 1.9s/it 40.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.3it/s 0.9s\n",
            "                   all         81        154      0.516      0.291      0.308      0.096\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     16/100      2.45G      1.589      1.195      1.646         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.0s/it 41.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.2it/s 0.9s\n",
            "                   all         81        154      0.701      0.699      0.747      0.279\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     17/100      2.45G      1.627      1.238      1.697         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.2s/it 47.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.5it/s 0.9s\n",
            "                   all         81        154       0.78      0.636      0.746      0.335\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     18/100      2.45G      1.541      1.146      1.619          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.0s/it 42.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.4it/s 0.9s\n",
            "                   all         81        154      0.531      0.422      0.453      0.154\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     19/100      2.45G      1.596      1.188      1.642         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 1.9s/it 39.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.3it/s 0.9s\n",
            "                   all         81        154       0.48      0.435      0.387      0.142\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     20/100      2.45G      1.594      1.142      1.633         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.1s/it 43.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.2it/s 0.9s\n",
            "                   all         81        154      0.928      0.935      0.973      0.517\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     21/100      2.45G      1.595      1.182      1.674          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.2s/it 46.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 2.1it/s 1.4s\n",
            "                   all         81        154      0.918      0.922      0.972      0.518\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     22/100      2.45G      1.529      1.127      1.608         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.0s/it 41.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 1.9it/s 1.6s\n",
            "                   all         81        154      0.721       0.76      0.791      0.377\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     23/100      2.45G      1.572      1.153      1.614         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.1s/it 44.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.6it/s 0.8s\n",
            "                   all         81        154       0.88      0.844      0.937      0.546\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     24/100      2.45G      1.525      1.137      1.574          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.1s/it 45.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 2.9it/s 1.0s\n",
            "                   all         81        154       0.87      0.909      0.958      0.532\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     25/100      2.45G      1.573      1.118      1.606          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.1s/it 43.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 2.5it/s 1.2s\n",
            "                   all         81        154      0.877      0.925      0.964      0.528\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     26/100      2.45G      1.542      1.123      1.577          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.0s/it 42.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 2.1it/s 1.4s\n",
            "                   all         81        154      0.862      0.932      0.953      0.516\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     27/100      2.45G      1.538      1.075      1.579          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.2s/it 45.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.0it/s 1.0s\n",
            "                   all         81        154      0.903       0.89      0.946      0.548\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     28/100      2.45G      1.494      1.047      1.579          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.0s/it 42.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.7it/s 0.8s\n",
            "                   all         81        154      0.942      0.956      0.988      0.591\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     29/100      2.45G      1.469     0.9969      1.542         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.1s/it 44.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 2.7it/s 1.1s\n",
            "                   all         81        154      0.921      0.906      0.966      0.545\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     30/100      2.45G      1.565      1.127      1.635         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.2s/it 45.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.6it/s 0.8s\n",
            "                   all         81        154      0.892      0.903      0.945      0.538\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     31/100      2.45G      1.502      1.061       1.57          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.1s/it 44.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 4.9it/s 0.6s\n",
            "                   all         81        154      0.919      0.963      0.976      0.541\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     32/100      2.45G      1.467      1.026      1.543          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.0s/it 42.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.4it/s 0.9s\n",
            "                   all         81        154      0.891      0.904       0.93      0.372\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     33/100      2.45G      1.459      1.027      1.542         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.3s/it 47.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 2.1it/s 1.5s\n",
            "                   all         81        154        0.8      0.844      0.839      0.268\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     34/100      2.45G       1.47       1.03      1.559         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.0s/it 42.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.2it/s 0.9s\n",
            "                   all         81        154      0.945      0.955      0.984      0.504\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     35/100      2.45G      1.445      1.015      1.542          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.1s/it 44.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.7it/s 0.8s\n",
            "                   all         81        154      0.883      0.538      0.641      0.279\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     36/100      2.45G      1.473      1.034      1.557         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.1s/it 44.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.4it/s 0.9s\n",
            "                   all         81        154      0.661      0.596      0.651      0.269\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     37/100      2.45G      1.394     0.9521      1.476         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.2s/it 46.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.0it/s 1.0s\n",
            "                   all         81        154       0.86      0.838      0.905      0.451\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     38/100      2.45G      1.489      1.017      1.589          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.1s/it 44.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 2.9it/s 1.0s\n",
            "                   all         81        154      0.417       0.24      0.275       0.13\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     39/100      2.45G      1.416     0.9906      1.518          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.0s/it 41.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.8it/s 0.8s\n",
            "                   all         81        154      0.943      0.974      0.988      0.599\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     40/100      2.45G      1.425     0.9665        1.5          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.1s/it 44.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 2.6it/s 1.1s\n",
            "                   all         81        154      0.956      0.961      0.989      0.621\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     41/100      2.45G      1.435      0.949       1.51          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.0s/it 42.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 2.1it/s 1.5s\n",
            "                   all         81        154      0.972      0.981      0.994      0.614\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     42/100      2.45G      1.454     0.9701      1.543          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.2s/it 46.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.2it/s 0.9s\n",
            "                   all         81        154      0.961      0.952      0.982       0.61\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     43/100      2.45G      1.459      1.006      1.539          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.1s/it 44.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.2it/s 0.9s\n",
            "                   all         81        154      0.897      0.849       0.92      0.561\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     44/100      2.45G       1.46     0.9939      1.549         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.1s/it 43.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 2.1it/s 1.4s\n",
            "                   all         81        154      0.917       0.79      0.899      0.524\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     45/100      2.45G      1.434     0.9792      1.544         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.0s/it 42.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.7it/s 0.8s\n",
            "                   all         81        154      0.929      0.942      0.976      0.582\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     46/100      2.45G      1.385     0.8954      1.466         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 1.9s/it 40.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.5it/s 0.8s\n",
            "                   all         81        154      0.922      0.961      0.984        0.6\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     47/100      2.45G      1.419     0.9404      1.512         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.0s/it 41.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.6it/s 0.8s\n",
            "                   all         81        154      0.955      0.974       0.99      0.544\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     48/100      2.45G      1.369     0.9248      1.457         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.1s/it 45.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.3it/s 0.9s\n",
            "                   all         81        154       0.98      0.987      0.994      0.642\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     49/100      2.45G      1.407     0.9552       1.49          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 1.9s/it 40.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.6it/s 0.8s\n",
            "                   all         81        154      0.945      0.948       0.98      0.575\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     50/100      2.48G      1.397     0.9257       1.48          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.0s/it 41.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.2it/s 0.9s\n",
            "                   all         81        154       0.98      0.979      0.993       0.67\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     51/100      2.48G      1.437     0.9176      1.512         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.1s/it 43.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 2.6it/s 1.1s\n",
            "                   all         81        154      0.993      0.979      0.994      0.666\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     52/100      2.48G      1.365     0.8929       1.47         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.1s/it 43.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 4.4it/s 0.7s\n",
            "                   all         81        154      0.968      0.988      0.994      0.618\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     53/100      2.48G      1.353     0.8927       1.46         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.0s/it 42.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 4.4it/s 0.7s\n",
            "                   all         81        154      0.973      0.974      0.993      0.629\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     54/100      2.48G       1.33      0.878      1.467          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.1s/it 44.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.6it/s 0.8s\n",
            "                   all         81        154      0.968       0.97      0.993      0.614\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     55/100      2.48G      1.357     0.8847      1.478          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.2s/it 45.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 2.2it/s 1.4s\n",
            "                   all         81        154      0.943      0.948      0.986      0.574\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     56/100      2.48G      1.334     0.8882      1.461          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 1.8s/it 38.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 2.0it/s 1.5s\n",
            "                   all         81        154      0.955       0.97       0.99      0.643\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     57/100      2.48G      1.361     0.9059       1.51          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.2s/it 45.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.6it/s 0.8s\n",
            "                   all         81        154      0.974      0.961      0.993      0.647\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     58/100      2.48G      1.342     0.8778      1.471          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.1s/it 43.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 4.1it/s 0.7s\n",
            "                   all         81        154      0.972      0.994      0.993       0.67\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     59/100      2.48G      1.309     0.8457      1.437          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.1s/it 43.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.3it/s 0.9s\n",
            "                   all         81        154      0.944      0.987       0.99       0.63\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     60/100      2.48G      1.341     0.8482       1.45          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.1s/it 43.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 2.0it/s 1.5s\n",
            "                   all         81        154      0.956      0.981      0.991      0.624\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     61/100      2.48G      1.297     0.8497      1.424          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.1s/it 45.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.1it/s 1.0s\n",
            "                   all         81        154       0.98       0.96      0.992      0.651\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     62/100      2.48G      1.364     0.8677      1.475          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.1s/it 45.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.2it/s 0.9s\n",
            "                   all         81        154       0.98      0.968       0.99      0.485\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     63/100      2.48G      1.286     0.8436      1.424          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.1s/it 43.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 2.3it/s 1.3s\n",
            "                   all         81        154      0.972      0.987      0.994      0.662\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     64/100      2.48G      1.291     0.8462      1.431          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.2s/it 45.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.6it/s 0.8s\n",
            "                   all         81        154      0.975      0.998      0.994      0.651\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     65/100      2.48G      1.323     0.8463      1.443          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 1.9s/it 40.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.5it/s 0.9s\n",
            "                   all         81        154      0.987      0.987      0.994      0.632\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     66/100      2.48G      1.268     0.8159        1.4         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.0s/it 42.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.2it/s 0.9s\n",
            "                   all         81        154      0.981       0.98      0.991      0.653\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     67/100      2.48G      1.271     0.8039      1.419          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.1s/it 43.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.2it/s 0.9s\n",
            "                   all         81        154      0.977      0.974      0.993      0.644\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     68/100      2.48G      1.309     0.7653      1.424          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 1.8s/it 37.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.7it/s 0.8s\n",
            "                   all         81        154      0.987       0.99      0.995      0.669\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     69/100      2.48G      1.273     0.8156      1.421          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 1.9s/it 39.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.7it/s 0.8s\n",
            "                   all         81        154      0.986      0.987      0.995      0.671\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     70/100      2.48G      1.277     0.8048      1.416         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 1.9s/it 39.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.8it/s 0.8s\n",
            "                   all         81        154      0.992      0.994      0.995      0.678\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     71/100      2.48G      1.265     0.7806      1.415          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.0s/it 41.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.7it/s 0.8s\n",
            "                   all         81        154      0.995      0.987      0.995      0.672\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     72/100      2.48G      1.261     0.7917      1.406          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.0s/it 41.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.5it/s 0.9s\n",
            "                   all         81        154      0.981      0.987      0.995      0.675\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     73/100      2.48G      1.266     0.7902      1.406          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.1s/it 45.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.5it/s 0.8s\n",
            "                   all         81        154      0.986      0.987      0.994      0.673\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     74/100      2.48G      1.341     0.9623      1.459          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 1.9s/it 39.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 2.3it/s 1.3s\n",
            "                   all         81        154      0.983      0.987      0.994      0.681\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     75/100      2.48G      1.205      0.757      1.372         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.2s/it 45.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.4it/s 0.9s\n",
            "                   all         81        154      0.981      0.987      0.994      0.682\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     76/100      2.48G      1.246     0.7728      1.424          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.1s/it 44.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.4it/s 0.9s\n",
            "                   all         81        154      0.974      0.981      0.994      0.673\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     77/100      2.48G       1.25       0.78      1.398          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.1s/it 43.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 2.7it/s 1.1s\n",
            "                   all         81        154      0.973      0.994      0.994      0.663\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     78/100      2.48G       1.26     0.7614      1.399          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.1s/it 43.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.2it/s 0.9s\n",
            "                   all         81        154      0.985      0.994      0.995      0.669\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     79/100      2.48G      1.295     0.8453      1.486          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.1s/it 45.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.8it/s 0.8s\n",
            "                   all         81        154      0.982      0.994      0.994      0.674\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     80/100      2.48G      1.231      0.781      1.388         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.0s/it 41.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 4.0it/s 0.8s\n",
            "                   all         81        154      0.981      0.985      0.993      0.673\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     81/100      2.48G      1.239     0.7712      1.392         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.1s/it 44.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 2.1it/s 1.4s\n",
            "                   all         81        154       0.98      0.987      0.993      0.684\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     82/100      2.48G      1.237     0.7592       1.37          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.1s/it 44.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.0it/s 1.0s\n",
            "                   all         81        154      0.981      0.991      0.994      0.666\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     83/100      2.48G      1.277     0.8027      1.426          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.1s/it 43.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.4it/s 0.9s\n",
            "                   all         81        154      0.981      0.998      0.995      0.694\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     84/100      2.48G      1.243     0.7546       1.39          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.0s/it 41.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.6it/s 0.8s\n",
            "                   all         81        154      0.992      0.987      0.995      0.706\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     85/100      2.48G      1.197     0.7481      1.369         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.1s/it 44.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 2.1it/s 1.4s\n",
            "                   all         81        154      0.998      0.987      0.995      0.704\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     86/100      2.48G      1.207     0.7278      1.366         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 1.9s/it 40.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 2.0it/s 1.5s\n",
            "                   all         81        154      0.993      0.992      0.994      0.694\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     87/100      2.48G      1.184     0.7508      1.364          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.1s/it 43.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.1it/s 1.0s\n",
            "                   all         81        154      0.998      0.987      0.995      0.705\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     88/100      2.48G      1.196     0.7256      1.358          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.1s/it 44.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 2.9it/s 1.0s\n",
            "                   all         81        154          1      0.986      0.995      0.703\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     89/100      2.48G      1.196      0.737      1.371          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.0s/it 41.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.3it/s 0.9s\n",
            "                   all         81        154      0.991      0.987      0.995      0.701\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     90/100      2.48G      1.233      0.734      1.364         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.1s/it 43.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 2.1it/s 1.5s\n",
            "                   all         81        154      0.999      0.987      0.995      0.707\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     91/100      2.48G      1.095     0.6481      1.299          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.3s/it 47.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 2.1it/s 1.4s\n",
            "                   all         81        154      0.995      0.987      0.995      0.708\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     92/100      2.48G      1.038     0.5805      1.262          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.0s/it 41.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 2.7it/s 1.1s\n",
            "                   all         81        154          1      0.992      0.995      0.698\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     93/100      2.48G      1.047      0.546      1.278          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 1.9s/it 40.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.5it/s 0.9s\n",
            "                   all         81        154      0.988      0.994      0.995      0.691\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     94/100      2.48G      1.038     0.5409      1.246          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.0s/it 41.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 4.0it/s 0.7s\n",
            "                   all         81        154      0.985      0.994      0.995       0.69\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     95/100      2.48G      1.074     0.5416      1.267          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.0s/it 41.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.2it/s 0.9s\n",
            "                   all         81        154      0.986      0.994      0.995      0.688\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     96/100      2.48G      1.053     0.5225      1.276          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.0s/it 42.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.1it/s 1.0s\n",
            "                   all         81        154      0.991      0.987      0.995      0.695\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     97/100      2.48G      1.042     0.5285      1.267          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 1.9s/it 39.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.4it/s 0.9s\n",
            "                   all         81        154          1      0.985      0.995      0.697\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     98/100      2.48G      1.015     0.5125      1.235          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.0s/it 42.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.7it/s 0.8s\n",
            "                   all         81        154          1      0.987      0.995      0.695\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     99/100      2.48G      1.038     0.5115      1.242          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.1s/it 44.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 2.2it/s 1.3s\n",
            "                   all         81        154          1      0.987      0.995      0.696\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    100/100      2.48G      1.051     0.5253      1.232          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 2.0s/it 41.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.0it/s 1.0s\n",
            "                   all         81        154          1      0.985      0.995      0.696\n",
            "\n",
            "100 epochs completed in 1.268 hours.\n",
            "Optimizer stripped from /content/runs/detect/fly_detector4/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/runs/detect/fly_detector4/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/runs/detect/fly_detector4/weights/best.pt...\n",
            "Ultralytics 8.3.238 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 1.5it/s 2.0s\n",
            "                   all         81        154      0.994      0.987      0.995      0.709\n",
            "Speed: 0.3ms preprocess, 2.7ms inference, 0.0ms loss, 5.8ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/fly_detector4\u001b[0m\n",
            "\n",
            "âœ… è®­ç»ƒå®Œæˆï¼\n",
            "æœ€ä½³æ¨¡å‹ä¿å­˜åœ¨: runs/detect/fly_detector/weights/best.pt\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "æœè‡ç›®æ ‡æ£€æµ‹è®­ç»ƒè„šæœ¬ï¼ˆYOLOv8ï¼‰\n",
        "ä½¿ç”¨YOLOv8è¿›è¡Œæœè‡æ£€æµ‹ï¼ˆä¸åŒºåˆ†ç±»åˆ«ï¼‰\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "\n",
        "\n",
        "class FlyDetectionTrainer:\n",
        "    def __init__(self, data_yaml, model_name='yolov8n.pt', epochs=100, img_size=640, batch_size=16):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data_yaml: æ•°æ®é…ç½®æ–‡ä»¶è·¯å¾„\n",
        "            model_name: é¢„è®­ç»ƒæ¨¡å‹åç§°\n",
        "            epochs: è®­ç»ƒè½®æ•°\n",
        "            img_size: å›¾åƒå°ºå¯¸\n",
        "            batch_size: æ‰¹æ¬¡å¤§å°\n",
        "        \"\"\"\n",
        "        self.data_yaml = data_yaml\n",
        "        self.model_name = model_name\n",
        "        self.epochs = epochs\n",
        "        self.img_size = img_size\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def train(self, project='runs/detect', name='fly_detector'):\n",
        "        \"\"\"è®­ç»ƒç›®æ ‡æ£€æµ‹æ¨¡å‹\"\"\"\n",
        "        print(\"=== å¼€å§‹è®­ç»ƒæœè‡æ£€æµ‹æ¨¡å‹ ===\")\n",
        "        print(f\"æ¨¡å‹: {self.model_name}\")\n",
        "        print(f\"æ•°æ®é…ç½®: {self.data_yaml}\")\n",
        "        print(f\"è®­ç»ƒè½®æ•°: {self.epochs}\")\n",
        "        print(f\"å›¾åƒå°ºå¯¸: {self.img_size}\")\n",
        "        print(f\"æ‰¹æ¬¡å¤§å°: {self.batch_size}\")\n",
        "        print(f\"è®¾å¤‡: {'cuda' if torch.cuda.is_available() else 'cpu'}\")\n",
        "\n",
        "        # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹\n",
        "        model = YOLO(self.model_name)\n",
        "\n",
        "        # è®­ç»ƒå‚æ•°\n",
        "        results = model.train(\n",
        "            data=self.data_yaml,\n",
        "            epochs=self.epochs,\n",
        "            imgsz=self.img_size,\n",
        "            batch=self.batch_size,\n",
        "            project=project,\n",
        "            name=name,\n",
        "            patience=20,  # æ—©åœè€å¿ƒå€¼\n",
        "            save=True,\n",
        "            save_period=10,  # æ¯10ä¸ªepochä¿å­˜ä¸€æ¬¡\n",
        "            # æ•°æ®å¢å¼º\n",
        "            hsv_h=0.015,\n",
        "            hsv_s=0.7,\n",
        "            hsv_v=0.4,\n",
        "            degrees=10.0,\n",
        "            translate=0.1,\n",
        "            scale=0.5,\n",
        "            shear=0.0,\n",
        "            perspective=0.0,\n",
        "            flipud=0.5,\n",
        "            fliplr=0.5,\n",
        "            mosaic=1.0,\n",
        "            mixup=0.1,\n",
        "            # ä¼˜åŒ–å™¨\n",
        "            optimizer='AdamW',\n",
        "            lr0=0.01,\n",
        "            lrf=0.01,\n",
        "            momentum=0.937,\n",
        "            weight_decay=0.0005,\n",
        "            warmup_epochs=3,\n",
        "            warmup_momentum=0.8,\n",
        "            warmup_bias_lr=0.1,\n",
        "            # å…¶ä»–\n",
        "            cos_lr=True,\n",
        "            label_smoothing=0.0,\n",
        "            box=7.5,\n",
        "            cls=0.5,\n",
        "            dfl=1.5,\n",
        "            plots=True,\n",
        "            verbose=True,\n",
        "        )\n",
        "\n",
        "        print(\"\\nâœ… è®­ç»ƒå®Œæˆï¼\")\n",
        "        print(f\"æœ€ä½³æ¨¡å‹ä¿å­˜åœ¨: {Path(project) / name / 'weights' / 'best.pt'}\")\n",
        "\n",
        "        return results\n",
        "\n",
        "    def validate(self, model_path, project='runs/detect', name='val'):\n",
        "        \"\"\"éªŒè¯æ¨¡å‹\"\"\"\n",
        "        print(\"\\n=== éªŒè¯æ¨¡å‹ ===\")\n",
        "        model = YOLO(model_path)\n",
        "\n",
        "        results = model.val(\n",
        "            data=self.data_yaml,\n",
        "            imgsz=self.img_size,\n",
        "            batch=self.batch_size,\n",
        "            project=project,\n",
        "            name=name,\n",
        "            plots=True,\n",
        "        )\n",
        "\n",
        "        print(\"\\néªŒè¯ç»“æœ:\")\n",
        "        print(f\"mAP50: {results.box.map50:.4f}\")\n",
        "        print(f\"mAP50-95: {results.box.map:.4f}\")\n",
        "        print(f\"Precision: {results.box.mp:.4f}\")\n",
        "        print(f\"Recall: {results.box.mr:.4f}\")\n",
        "\n",
        "        return results\n",
        "\n",
        "\n",
        "def main():\n",
        "    # é…ç½®å‚æ•°\n",
        "    data_yaml = \"datasets/detection/data.yaml\"\n",
        "\n",
        "    # åˆ›å»ºè®­ç»ƒå™¨\n",
        "    trainer = FlyDetectionTrainer(\n",
        "        data_yaml=data_yaml,\n",
        "        model_name='yolo11n.pt',  # å¯é€‰: yolov8s.pt, yolov8m.pt, yolov8l.pt, yolov8x.pt\n",
        "        epochs=100,\n",
        "        img_size=640,\n",
        "        batch_size=16,\n",
        "    )\n",
        "\n",
        "    # è®­ç»ƒæ¨¡å‹\n",
        "    results = trainer.train(project='runs/detect', name='fly_detector')\n",
        "\n",
        "    # éªŒè¯æœ€ä½³æ¨¡å‹\n",
        "    best_model_path = 'runs/detect/fly_detector/weights/best.pt'\n",
        "    if Path(best_model_path).exists():\n",
        "        trainer.validate(best_model_path, project='runs/detect', name='val_best')\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a86f880d",
      "metadata": {
        "id": "a86f880d"
      },
      "source": [
        "## train_classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "7d3b3662",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7d3b3662",
        "outputId": "e6f1fd86-7429-410a-fb4b-3f2acad287d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainé›†: 562 ä¸ªæ ·æœ¬\n",
            "valé›†: 138 ä¸ªæ ·æœ¬\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97.8M/97.8M [00:00<00:00, 182MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "æ¨¡å‹: resnet50, è®¾å¤‡: cuda, ç±»åˆ«æ•°: 2\n",
            "\n",
            "=== å¼€å§‹è®­ç»ƒ ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.15it/s, loss=0.5584, acc=71.17%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50: Train Loss: 0.6986, Train Acc: 71.17%, Val Loss: 55.8572, Val Acc: 21.01%, LR: 0.000999\n",
            "âœ… ä¿å­˜æœ€ä½³æ¨¡å‹ (Val Acc: 21.01%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.18it/s, loss=0.2452, acc=76.69%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/50: Train Loss: 0.5251, Train Acc: 76.69%, Val Loss: 0.6792, Val Acc: 77.54%, LR: 0.000996\n",
            "âœ… ä¿å­˜æœ€ä½³æ¨¡å‹ (Val Acc: 77.54%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:14<00:00,  1.20it/s, loss=0.3319, acc=76.51%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/50: Train Loss: 0.5201, Train Acc: 76.51%, Val Loss: 0.5875, Val Acc: 78.26%, LR: 0.000991\n",
            "âœ… ä¿å­˜æœ€ä½³æ¨¡å‹ (Val Acc: 78.26%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.20it/s, loss=0.5150, acc=75.62%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/50: Train Loss: 0.5638, Train Acc: 75.62%, Val Loss: 0.6954, Val Acc: 78.26%, LR: 0.000984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.17it/s, loss=0.8884, acc=76.69%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/50: Train Loss: 0.5525, Train Acc: 76.69%, Val Loss: 1.1810, Val Acc: 78.26%, LR: 0.000976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.16it/s, loss=0.4512, acc=76.51%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/50: Train Loss: 0.5344, Train Acc: 76.51%, Val Loss: 0.5908, Val Acc: 79.71%, LR: 0.000965\n",
            "âœ… ä¿å­˜æœ€ä½³æ¨¡å‹ (Val Acc: 79.71%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.10it/s, loss=0.8155, acc=77.76%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/50: Train Loss: 0.5458, Train Acc: 77.76%, Val Loss: 0.6766, Val Acc: 76.81%, LR: 0.000952\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.17it/s, loss=0.3345, acc=77.40%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/50: Train Loss: 0.4972, Train Acc: 77.40%, Val Loss: 0.5356, Val Acc: 79.71%, LR: 0.000938\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.14it/s, loss=0.6611, acc=78.29%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/50: Train Loss: 0.5044, Train Acc: 78.29%, Val Loss: 0.4916, Val Acc: 83.33%, LR: 0.000922\n",
            "âœ… ä¿å­˜æœ€ä½³æ¨¡å‹ (Val Acc: 83.33%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.15it/s, loss=0.5364, acc=78.65%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/50: Train Loss: 0.4587, Train Acc: 78.65%, Val Loss: 0.6571, Val Acc: 78.99%, LR: 0.000905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.17it/s, loss=0.6756, acc=80.78%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/50: Train Loss: 0.4533, Train Acc: 80.78%, Val Loss: 0.8677, Val Acc: 78.26%, LR: 0.000885\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.14it/s, loss=0.3360, acc=79.00%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/50: Train Loss: 0.4556, Train Acc: 79.00%, Val Loss: 0.9165, Val Acc: 63.04%, LR: 0.000864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.17it/s, loss=0.5198, acc=77.58%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/50: Train Loss: 0.4587, Train Acc: 77.58%, Val Loss: 0.4902, Val Acc: 84.06%, LR: 0.000842\n",
            "âœ… ä¿å­˜æœ€ä½³æ¨¡å‹ (Val Acc: 84.06%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.14it/s, loss=0.3460, acc=81.14%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/50: Train Loss: 0.4346, Train Acc: 81.14%, Val Loss: 0.9951, Val Acc: 80.43%, LR: 0.000819\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.17it/s, loss=0.8952, acc=81.14%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/50: Train Loss: 0.4311, Train Acc: 81.14%, Val Loss: 0.4776, Val Acc: 81.88%, LR: 0.000794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.18it/s, loss=0.2059, acc=80.25%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/50: Train Loss: 0.3878, Train Acc: 80.25%, Val Loss: 0.5142, Val Acc: 77.54%, LR: 0.000768\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.18it/s, loss=0.3233, acc=81.67%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/50: Train Loss: 0.4211, Train Acc: 81.67%, Val Loss: 0.5279, Val Acc: 82.61%, LR: 0.000741\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.16it/s, loss=0.3720, acc=83.27%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/50: Train Loss: 0.4100, Train Acc: 83.27%, Val Loss: 0.6643, Val Acc: 80.43%, LR: 0.000713\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.18it/s, loss=0.3930, acc=83.10%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/50: Train Loss: 0.4045, Train Acc: 83.10%, Val Loss: 0.4685, Val Acc: 86.23%, LR: 0.000684\n",
            "âœ… ä¿å­˜æœ€ä½³æ¨¡å‹ (Val Acc: 86.23%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.13it/s, loss=0.4327, acc=82.56%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/50: Train Loss: 0.4000, Train Acc: 82.56%, Val Loss: 0.4344, Val Acc: 86.23%, LR: 0.000655\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.16it/s, loss=0.2088, acc=84.16%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/50: Train Loss: 0.3787, Train Acc: 84.16%, Val Loss: 0.4266, Val Acc: 84.78%, LR: 0.000624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.16it/s, loss=0.2565, acc=84.88%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22/50: Train Loss: 0.3477, Train Acc: 84.88%, Val Loss: 0.5251, Val Acc: 84.78%, LR: 0.000594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.16it/s, loss=0.3593, acc=81.85%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23/50: Train Loss: 0.4079, Train Acc: 81.85%, Val Loss: 0.9620, Val Acc: 61.59%, LR: 0.000563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:14<00:00,  1.21it/s, loss=0.2620, acc=83.45%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24/50: Train Loss: 0.3652, Train Acc: 83.45%, Val Loss: 0.6731, Val Acc: 78.99%, LR: 0.000531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.19it/s, loss=0.1731, acc=86.48%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25/50: Train Loss: 0.3216, Train Acc: 86.48%, Val Loss: 0.3611, Val Acc: 86.96%, LR: 0.000500\n",
            "âœ… ä¿å­˜æœ€ä½³æ¨¡å‹ (Val Acc: 86.96%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.16it/s, loss=0.3137, acc=85.23%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26/50: Train Loss: 0.3571, Train Acc: 85.23%, Val Loss: 0.4268, Val Acc: 84.06%, LR: 0.000469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.20it/s, loss=0.8365, acc=87.37%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27/50: Train Loss: 0.3320, Train Acc: 87.37%, Val Loss: 0.3811, Val Acc: 86.96%, LR: 0.000437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.17it/s, loss=0.6769, acc=87.90%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28/50: Train Loss: 0.3159, Train Acc: 87.90%, Val Loss: 0.4957, Val Acc: 84.06%, LR: 0.000406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.14it/s, loss=0.2472, acc=87.54%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29/50: Train Loss: 0.2998, Train Acc: 87.54%, Val Loss: 0.4613, Val Acc: 84.78%, LR: 0.000376\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.17it/s, loss=0.3397, acc=87.19%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30/50: Train Loss: 0.3172, Train Acc: 87.19%, Val Loss: 0.3604, Val Acc: 89.13%, LR: 0.000345\n",
            "âœ… ä¿å­˜æœ€ä½³æ¨¡å‹ (Val Acc: 89.13%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 31/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.17it/s, loss=0.0971, acc=90.04%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31/50: Train Loss: 0.2694, Train Acc: 90.04%, Val Loss: 0.4993, Val Acc: 86.23%, LR: 0.000316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 32/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.15it/s, loss=0.0940, acc=90.04%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32/50: Train Loss: 0.2463, Train Acc: 90.04%, Val Loss: 0.4796, Val Acc: 85.51%, LR: 0.000287\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 33/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.17it/s, loss=0.3129, acc=89.68%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33/50: Train Loss: 0.2614, Train Acc: 89.68%, Val Loss: 0.3857, Val Acc: 84.06%, LR: 0.000259\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 34/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.16it/s, loss=0.4482, acc=88.97%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34/50: Train Loss: 0.2570, Train Acc: 88.97%, Val Loss: 0.3573, Val Acc: 87.68%, LR: 0.000232\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 35/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.18it/s, loss=0.1803, acc=93.42%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35/50: Train Loss: 0.2109, Train Acc: 93.42%, Val Loss: 0.3104, Val Acc: 89.86%, LR: 0.000206\n",
            "âœ… ä¿å­˜æœ€ä½³æ¨¡å‹ (Val Acc: 89.86%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 36/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.14it/s, loss=0.4813, acc=90.75%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36/50: Train Loss: 0.2372, Train Acc: 90.75%, Val Loss: 0.3425, Val Acc: 89.86%, LR: 0.000181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 37/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.14it/s, loss=0.1856, acc=91.10%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37/50: Train Loss: 0.2339, Train Acc: 91.10%, Val Loss: 0.3539, Val Acc: 89.13%, LR: 0.000158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 38/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.17it/s, loss=0.7037, acc=91.99%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38/50: Train Loss: 0.2242, Train Acc: 91.99%, Val Loss: 0.3850, Val Acc: 89.13%, LR: 0.000136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 39/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.17it/s, loss=0.1007, acc=92.88%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39/50: Train Loss: 0.1896, Train Acc: 92.88%, Val Loss: 0.3635, Val Acc: 87.68%, LR: 0.000115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 40/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.15it/s, loss=0.1478, acc=93.77%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40/50: Train Loss: 0.1694, Train Acc: 93.77%, Val Loss: 0.4256, Val Acc: 86.96%, LR: 0.000095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 41/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.17it/s, loss=0.1347, acc=94.31%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41/50: Train Loss: 0.1613, Train Acc: 94.31%, Val Loss: 0.4453, Val Acc: 86.23%, LR: 0.000078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 42/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.18it/s, loss=0.2709, acc=94.84%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42/50: Train Loss: 0.1568, Train Acc: 94.84%, Val Loss: 0.4346, Val Acc: 88.41%, LR: 0.000062\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 43/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.16it/s, loss=0.0856, acc=95.73%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43/50: Train Loss: 0.1244, Train Acc: 95.73%, Val Loss: 0.3652, Val Acc: 88.41%, LR: 0.000048\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 44/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.17it/s, loss=0.0312, acc=96.26%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44/50: Train Loss: 0.1250, Train Acc: 96.26%, Val Loss: 0.3417, Val Acc: 86.96%, LR: 0.000035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 45/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.17it/s, loss=0.0624, acc=96.09%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45/50: Train Loss: 0.1231, Train Acc: 96.09%, Val Loss: 0.3630, Val Acc: 89.13%, LR: 0.000024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 46/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.14it/s, loss=0.0531, acc=95.55%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46/50: Train Loss: 0.1304, Train Acc: 95.55%, Val Loss: 0.3971, Val Acc: 87.68%, LR: 0.000016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 47/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.16it/s, loss=0.1312, acc=95.55%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47/50: Train Loss: 0.1279, Train Acc: 95.55%, Val Loss: 0.3764, Val Acc: 89.86%, LR: 0.000009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 48/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.19it/s, loss=0.0817, acc=95.55%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48/50: Train Loss: 0.1274, Train Acc: 95.55%, Val Loss: 0.3622, Val Acc: 89.86%, LR: 0.000004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 49/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.15it/s, loss=0.0713, acc=95.73%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49/50: Train Loss: 0.1271, Train Acc: 95.73%, Val Loss: 0.3578, Val Acc: 89.86%, LR: 0.000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 50/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:15<00:00,  1.17it/s, loss=0.2244, acc=95.91%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50/50: Train Loss: 0.1215, Train Acc: 95.91%, Val Loss: 0.3629, Val Acc: 89.86%, LR: 0.000000\n",
            "è®­ç»ƒæ›²çº¿ä¿å­˜åœ¨: runs/classification/training_history.png\n",
            "\n",
            "âœ… è®­ç»ƒå®Œæˆï¼æœ€ä½³éªŒè¯å‡†ç¡®ç‡: 89.86%\n",
            "æ¨¡å‹ä¿å­˜åœ¨: runs/classification/best_model.pth\n",
            "\n",
            "=== è¯„ä¼°æ¨¡å‹ ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "è¯„ä¼°ä¸­: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:03<00:00,  1.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "åˆ†ç±»æŠ¥å‘Š:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Long       0.91      0.96      0.94       108\n",
            "       Short       0.83      0.67      0.74        30\n",
            "\n",
            "    accuracy                           0.90       138\n",
            "   macro avg       0.87      0.81      0.84       138\n",
            "weighted avg       0.90      0.90      0.89       138\n",
            "\n",
            "\n",
            "æ··æ·†çŸ©é˜µä¿å­˜åœ¨: runs/classification/confusion_matrix.png\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\"\"\"\n",
        "æœè‡ç¿…è†€åˆ†ç±»è®­ç»ƒè„šæœ¬\n",
        "ä½¿ç”¨ResNetè¿›è¡Œé•¿ç¿…/çŸ­ç¿…åˆ†ç±»\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "class FlyClassificationDataset(Dataset):\n",
        "    \"\"\"æœè‡åˆ†ç±»æ•°æ®é›†\"\"\"\n",
        "    def __init__(self, data_root, split='train', transform=None, exclude_ambiguous=True):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data_root: æ•°æ®æ ¹ç›®å½•\n",
        "            split: 'train' æˆ– 'val'\n",
        "            transform: æ•°æ®è½¬æ¢\n",
        "            exclude_ambiguous: æ˜¯å¦æ’é™¤Ambiguousç±»åˆ«\n",
        "        \"\"\"\n",
        "        self.data_root = Path(data_root) / split\n",
        "        self.transform = transform\n",
        "\n",
        "        # ç±»åˆ«æ˜ å°„\n",
        "        if exclude_ambiguous:\n",
        "            self.class_to_idx = {'Long': 0, 'Short': 1}\n",
        "            self.classes = ['Long', 'Short']\n",
        "        else:\n",
        "            self.class_to_idx = {'Ambiguous': 0, 'Long': 1, 'Short': 2}\n",
        "            self.classes = ['Ambiguous', 'Long', 'Short']\n",
        "\n",
        "        # åŠ è½½å›¾åƒè·¯å¾„\n",
        "        self.samples = []\n",
        "        for class_name in self.classes:\n",
        "            class_dir = self.data_root / class_name\n",
        "            if not class_dir.exists():\n",
        "                continue\n",
        "            for img_path in class_dir.glob('*.jpg'):\n",
        "                self.samples.append((str(img_path), self.class_to_idx[class_name]))\n",
        "\n",
        "        print(f\"{split}é›†: {len(self.samples)} ä¸ªæ ·æœ¬\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.samples[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "\n",
        "class FlyClassifier:\n",
        "    def __init__(self, num_classes=2, model_name='resnet50', pretrained=True):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            num_classes: ç±»åˆ«æ•°é‡\n",
        "            model_name: æ¨¡å‹åç§° ('resnet18', 'resnet50', 'efficientnet_b0', etc.)\n",
        "            pretrained: æ˜¯å¦ä½¿ç”¨é¢„è®­ç»ƒæƒé‡\n",
        "        \"\"\"\n",
        "        self.num_classes = num_classes\n",
        "        self.model_name = model_name\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        # åˆ›å»ºæ¨¡å‹\n",
        "        self.model = self._create_model(pretrained)\n",
        "        self.model = self.model.to(self.device)\n",
        "\n",
        "        print(f\"æ¨¡å‹: {model_name}, è®¾å¤‡: {self.device}, ç±»åˆ«æ•°: {num_classes}\")\n",
        "\n",
        "    def _create_model(self, pretrained):\n",
        "        \"\"\"åˆ›å»ºæ¨¡å‹\"\"\"\n",
        "        if self.model_name == 'resnet18':\n",
        "            model = models.resnet18(pretrained=pretrained)\n",
        "            model.fc = nn.Linear(model.fc.in_features, self.num_classes)\n",
        "        elif self.model_name == 'resnet50':\n",
        "            model = models.resnet50(pretrained=pretrained)\n",
        "            model.fc = nn.Linear(model.fc.in_features, self.num_classes)\n",
        "        elif self.model_name == 'efficientnet_b0':\n",
        "            model = models.efficientnet_b0(pretrained=pretrained)\n",
        "            model.classifier[1] = nn.Linear(model.classifier[1].in_features, self.num_classes)\n",
        "        elif self.model_name == 'mobilenet_v2':\n",
        "            model = models.mobilenet_v2(pretrained=pretrained)\n",
        "            model.classifier[1] = nn.Linear(model.classifier[1].in_features, self.num_classes)\n",
        "        else:\n",
        "            raise ValueError(f\"ä¸æ”¯æŒçš„æ¨¡å‹: {self.model_name}\")\n",
        "\n",
        "        return model\n",
        "\n",
        "    def train(self, train_loader, val_loader, epochs=50, lr=0.001, save_dir='runs/classification'):\n",
        "        \"\"\"è®­ç»ƒæ¨¡å‹\"\"\"\n",
        "        save_dir = Path(save_dir)\n",
        "        save_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.AdamW(self.model.parameters(), lr=lr, weight_decay=0.01)\n",
        "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "\n",
        "        best_acc = 0.0\n",
        "        history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
        "\n",
        "        print(\"\\n=== å¼€å§‹è®­ç»ƒ ===\")\n",
        "        for epoch in range(epochs):\n",
        "            # è®­ç»ƒé˜¶æ®µ\n",
        "            self.model.train()\n",
        "            train_loss = 0.0\n",
        "            train_correct = 0\n",
        "            train_total = 0\n",
        "\n",
        "            pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
        "            for images, labels in pbar:\n",
        "                images, labels = images.to(self.device), labels.to(self.device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                outputs = self.model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                train_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                train_total += labels.size(0)\n",
        "                train_correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "                pbar.set_postfix({'loss': f'{loss.item():.4f}',\n",
        "                                 'acc': f'{100.*train_correct/train_total:.2f}%'})\n",
        "\n",
        "            train_loss /= len(train_loader)\n",
        "            train_acc = 100. * train_correct / train_total\n",
        "\n",
        "            # éªŒè¯é˜¶æ®µ\n",
        "            val_loss, val_acc = self.validate(val_loader, criterion)\n",
        "\n",
        "            # æ›´æ–°å­¦ä¹ ç‡\n",
        "            scheduler.step()\n",
        "\n",
        "            # è®°å½•å†å²\n",
        "            history['train_loss'].append(train_loss)\n",
        "            history['train_acc'].append(train_acc)\n",
        "            history['val_loss'].append(val_loss)\n",
        "            history['val_acc'].append(val_acc)\n",
        "\n",
        "            print(f\"Epoch {epoch+1}/{epochs}: \"\n",
        "                  f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, \"\n",
        "                  f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%, \"\n",
        "                  f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "\n",
        "            # ä¿å­˜æœ€ä½³æ¨¡å‹\n",
        "            if val_acc > best_acc:\n",
        "                best_acc = val_acc\n",
        "                torch.save({\n",
        "                    'epoch': epoch,\n",
        "                    'model_state_dict': self.model.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    'best_acc': best_acc,\n",
        "                    'model_name': self.model_name,\n",
        "                    'num_classes': self.num_classes,\n",
        "                }, save_dir / 'best_model.pth')\n",
        "                print(f\"âœ… ä¿å­˜æœ€ä½³æ¨¡å‹ (Val Acc: {val_acc:.2f}%)\")\n",
        "\n",
        "        # ä¿å­˜è®­ç»ƒå†å²\n",
        "        with open(save_dir / 'history.json', 'w') as f:\n",
        "            json.dump(history, f, indent=2)\n",
        "\n",
        "        # ç»˜åˆ¶è®­ç»ƒæ›²çº¿\n",
        "        self.plot_history(history, save_dir)\n",
        "\n",
        "        print(f\"\\nâœ… è®­ç»ƒå®Œæˆï¼æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_acc:.2f}%\")\n",
        "        print(f\"æ¨¡å‹ä¿å­˜åœ¨: {save_dir / 'best_model.pth'}\")\n",
        "\n",
        "        return history\n",
        "\n",
        "    def validate(self, val_loader, criterion=None):\n",
        "        \"\"\"éªŒè¯æ¨¡å‹\"\"\"\n",
        "        self.model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "\n",
        "        if criterion is None:\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(self.device), labels.to(self.device)\n",
        "                outputs = self.model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        val_acc = 100. * val_correct / val_total\n",
        "\n",
        "        return val_loss, val_acc\n",
        "\n",
        "    def evaluate(self, test_loader, class_names, save_dir='runs/classification'):\n",
        "        \"\"\"è¯¦ç»†è¯„ä¼°æ¨¡å‹\"\"\"\n",
        "        self.model.eval()\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "\n",
        "        print(\"\\n=== è¯„ä¼°æ¨¡å‹ ===\")\n",
        "        with torch.no_grad():\n",
        "            for images, labels in tqdm(test_loader, desc=\"è¯„ä¼°ä¸­\"):\n",
        "                images = images.to(self.device)\n",
        "                outputs = self.model(images)\n",
        "                _, predicted = outputs.max(1)\n",
        "\n",
        "                all_preds.extend(predicted.cpu().numpy())\n",
        "                all_labels.extend(labels.numpy())\n",
        "\n",
        "        # åˆ†ç±»æŠ¥å‘Š\n",
        "        print(\"\\nåˆ†ç±»æŠ¥å‘Š:\")\n",
        "        print(classification_report(all_labels, all_preds, target_names=class_names))\n",
        "\n",
        "        # æ··æ·†çŸ©é˜µ\n",
        "        cm = confusion_matrix(all_labels, all_preds)\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                    xticklabels=class_names, yticklabels=class_names)\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.ylabel('True Label')\n",
        "        plt.xlabel('Predicted Label')\n",
        "        plt.tight_layout()\n",
        "\n",
        "        save_dir = Path(save_dir)\n",
        "        plt.savefig(save_dir / 'confusion_matrix.png')\n",
        "        print(f\"\\næ··æ·†çŸ©é˜µä¿å­˜åœ¨: {save_dir / 'confusion_matrix.png'}\")\n",
        "\n",
        "        return all_preds, all_labels\n",
        "\n",
        "    def plot_history(self, history, save_dir):\n",
        "        \"\"\"ç»˜åˆ¶è®­ç»ƒå†å²\"\"\"\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "        # Loss\n",
        "        ax1.plot(history['train_loss'], label='Train Loss')\n",
        "        ax1.plot(history['val_loss'], label='Val Loss')\n",
        "        ax1.set_xlabel('Epoch')\n",
        "        ax1.set_ylabel('Loss')\n",
        "        ax1.set_title('Training and Validation Loss')\n",
        "        ax1.legend()\n",
        "        ax1.grid(True)\n",
        "\n",
        "        # Accuracy\n",
        "        ax2.plot(history['train_acc'], label='Train Acc')\n",
        "        ax2.plot(history['val_acc'], label='Val Acc')\n",
        "        ax2.set_xlabel('Epoch')\n",
        "        ax2.set_ylabel('Accuracy (%)')\n",
        "        ax2.set_title('Training and Validation Accuracy')\n",
        "        ax2.legend()\n",
        "        ax2.grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(Path(save_dir) / 'training_history.png')\n",
        "        print(f\"è®­ç»ƒæ›²çº¿ä¿å­˜åœ¨: {Path(save_dir) / 'training_history.png'}\")\n",
        "\n",
        "    def load_model(self, model_path):\n",
        "        \"\"\"åŠ è½½æ¨¡å‹\"\"\"\n",
        "        checkpoint = torch.load(model_path, map_location=self.device)\n",
        "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        print(f\"åŠ è½½æ¨¡å‹: {model_path}\")\n",
        "        print(f\"æœ€ä½³å‡†ç¡®ç‡: {checkpoint['best_acc']:.2f}%\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    # é…ç½®å‚æ•°\n",
        "    data_root = \"datasets/classification\"\n",
        "    batch_size = 32\n",
        "    num_epochs = 50\n",
        "    learning_rate = 0.001\n",
        "    img_size = 224\n",
        "\n",
        "    # æ•°æ®è½¬æ¢\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.Resize((img_size, img_size)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        transforms.RandomRotation(15),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    val_transform = transforms.Compose([\n",
        "        transforms.Resize((img_size, img_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    # åˆ›å»ºæ•°æ®é›†\n",
        "    train_dataset = FlyClassificationDataset(data_root, 'train', train_transform, exclude_ambiguous=True)\n",
        "    val_dataset = FlyClassificationDataset(data_root, 'val', val_transform, exclude_ambiguous=True)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "    # åˆ›å»ºåˆ†ç±»å™¨\n",
        "    classifier = FlyClassifier(num_classes=2, model_name='resnet50', pretrained=True)\n",
        "\n",
        "    # è®­ç»ƒ\n",
        "    history = classifier.train(train_loader, val_loader, epochs=num_epochs, lr=learning_rate)\n",
        "\n",
        "    # è¯„ä¼°\n",
        "    classifier.evaluate(val_loader, class_names=['Long', 'Short'])\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "085bdfe6",
      "metadata": {
        "id": "085bdfe6"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82bd7212",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "82bd7212"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "ç«¯åˆ°ç«¯æ¨ç†è„šæœ¬\n",
        "å®Œæ•´çš„æ£€æµ‹+åˆ†ç±»æµç¨‹\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from ultralytics import YOLO\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "\n",
        "class FlyDetectionClassificationPipeline:\n",
        "    \"\"\"æœè‡æ£€æµ‹å’Œåˆ†ç±»ç«¯åˆ°ç«¯æµç¨‹\"\"\"\n",
        "\n",
        "    def __init__(self, detection_model_path, classification_model_path,\n",
        "                 classification_model_name='resnet50', num_classes=2, conf_threshold=0.25):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            detection_model_path: æ£€æµ‹æ¨¡å‹è·¯å¾„\n",
        "            classification_model_path: åˆ†ç±»æ¨¡å‹è·¯å¾„\n",
        "            classification_model_name: åˆ†ç±»æ¨¡å‹åç§°\n",
        "            num_classes: åˆ†ç±»ç±»åˆ«æ•°\n",
        "            conf_threshold: æ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼\n",
        "        \"\"\"\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.conf_threshold = conf_threshold\n",
        "\n",
        "        # åŠ è½½æ£€æµ‹æ¨¡å‹\n",
        "        print(\"åŠ è½½æ£€æµ‹æ¨¡å‹...\")\n",
        "        self.detection_model = YOLO(detection_model_path)\n",
        "\n",
        "        # åŠ è½½åˆ†ç±»æ¨¡å‹\n",
        "        print(\"åŠ è½½åˆ†ç±»æ¨¡å‹...\")\n",
        "        self.classification_model = self._load_classification_model(\n",
        "            classification_model_path, classification_model_name, num_classes\n",
        "        )\n",
        "\n",
        "        # åˆ†ç±»ç±»åˆ«\n",
        "        self.class_names = ['Long', 'Short']\n",
        "\n",
        "        # åˆ†ç±»å›¾åƒè½¬æ¢\n",
        "        self.classification_transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        print(f\"âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼è®¾å¤‡: {self.device}\")\n",
        "\n",
        "    def _load_classification_model(self, model_path, model_name, num_classes):\n",
        "        \"\"\"åŠ è½½åˆ†ç±»æ¨¡å‹\"\"\"\n",
        "        # åˆ›å»ºæ¨¡å‹æ¶æ„\n",
        "        if model_name == 'resnet18':\n",
        "            model = models.resnet18()\n",
        "            model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "        elif model_name == 'resnet50':\n",
        "            model = models.resnet50()\n",
        "            model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "        elif model_name == 'efficientnet_b0':\n",
        "            model = models.efficientnet_b0()\n",
        "            model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
        "        elif model_name == 'mobilenet_v2':\n",
        "            model = models.mobilenet_v2()\n",
        "            model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
        "        else:\n",
        "            raise ValueError(f\"ä¸æ”¯æŒçš„æ¨¡å‹: {model_name}\")\n",
        "\n",
        "        # åŠ è½½æƒé‡\n",
        "        checkpoint = torch.load(model_path, map_location=self.device)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        model = model.to(self.device)\n",
        "        model.eval()\n",
        "\n",
        "        return model\n",
        "\n",
        "    def detect_flies(self, image):\n",
        "        \"\"\"æ£€æµ‹å›¾åƒä¸­çš„æœè‡\n",
        "\n",
        "        Args:\n",
        "            image: PIL Image æˆ– numpy array\n",
        "\n",
        "        Returns:\n",
        "            boxes: æ£€æµ‹æ¡† [[x1, y1, x2, y2, conf], ...]\n",
        "        \"\"\"\n",
        "        results = self.detection_model(image, conf=self.conf_threshold, verbose=False)\n",
        "\n",
        "        boxes = []\n",
        "        for result in results:\n",
        "            for box in result.boxes:\n",
        "                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
        "                conf = box.conf[0].cpu().numpy()\n",
        "                boxes.append([x1, y1, x2, y2, conf])\n",
        "\n",
        "        return np.array(boxes) if boxes else np.array([]).reshape(0, 5)\n",
        "\n",
        "    def classify_fly(self, image, box):\n",
        "        \"\"\"å¯¹æ£€æµ‹åˆ°çš„æœè‡è¿›è¡Œåˆ†ç±»\n",
        "\n",
        "        Args:\n",
        "            image: PIL Image\n",
        "            box: [x1, y1, x2, y2, conf]\n",
        "\n",
        "        Returns:\n",
        "            class_name: ç±»åˆ«åç§°\n",
        "            confidence: åˆ†ç±»ç½®ä¿¡åº¦\n",
        "        \"\"\"\n",
        "        x1, y1, x2, y2 = map(int, box[:4])\n",
        "\n",
        "        # è£å‰ªæœè‡åŒºåŸŸ\n",
        "        cropped = image.crop((x1, y1, x2, y2))\n",
        "\n",
        "        # è½¬æ¢å›¾åƒ\n",
        "        img_tensor = self.classification_transform(cropped).unsqueeze(0).to(self.device)\n",
        "\n",
        "        # åˆ†ç±»\n",
        "        with torch.no_grad():\n",
        "            outputs = self.classification_model(img_tensor)\n",
        "            probs = torch.softmax(outputs, dim=1)\n",
        "            confidence, predicted = torch.max(probs, 1)\n",
        "\n",
        "        class_name = self.class_names[predicted.item()]\n",
        "        confidence = confidence.item()\n",
        "\n",
        "        return class_name, confidence\n",
        "\n",
        "    def process_image(self, image_path, save_path=None, save_crops=False, crops_dir=None):\n",
        "        \"\"\"å¤„ç†å•å¼ å›¾åƒ\n",
        "\n",
        "        Args:\n",
        "            image_path: å›¾åƒè·¯å¾„\n",
        "            save_path: ç»“æœä¿å­˜è·¯å¾„\n",
        "            save_crops: æ˜¯å¦ä¿å­˜è£å‰ªçš„æœè‡å›¾åƒ\n",
        "            crops_dir: è£å‰ªå›¾åƒä¿å­˜ç›®å½•\n",
        "\n",
        "        Returns:\n",
        "            results: [{'box': [x1, y1, x2, y2], 'det_conf': conf,\n",
        "                      'class': class_name, 'cls_conf': conf}, ...]\n",
        "        \"\"\"\n",
        "        # è¯»å–å›¾åƒ\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "\n",
        "        # æ£€æµ‹æœè‡\n",
        "        boxes = self.detect_flies(image)\n",
        "\n",
        "        results = []\n",
        "        for i, box in enumerate(boxes):\n",
        "            # åˆ†ç±»\n",
        "            class_name, cls_conf = self.classify_fly(image, box)\n",
        "\n",
        "            result = {\n",
        "                'box': box[:4].tolist(),\n",
        "                'det_conf': float(box[4]),\n",
        "                'class': class_name,\n",
        "                'cls_conf': float(cls_conf)\n",
        "            }\n",
        "            results.append(result)\n",
        "\n",
        "            # ä¿å­˜è£å‰ªå›¾åƒ\n",
        "            if save_crops and crops_dir:\n",
        "                x1, y1, x2, y2 = map(int, box[:4])\n",
        "                cropped = image.crop((x1, y1, x2, y2))\n",
        "                crop_path = Path(crops_dir) / class_name / f\"{Path(image_path).stem}_{i}.jpg\"\n",
        "                crop_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "                cropped.save(crop_path)\n",
        "\n",
        "        # å¯è§†åŒ–å¹¶ä¿å­˜\n",
        "        if save_path:\n",
        "            self.visualize_results(image_path, results, save_path)\n",
        "\n",
        "        return results\n",
        "\n",
        "    def process_batch(self, image_dir, output_dir, save_crops=False):\n",
        "        \"\"\"æ‰¹é‡å¤„ç†å›¾åƒ\n",
        "\n",
        "        Args:\n",
        "            image_dir: å›¾åƒç›®å½•\n",
        "            output_dir: è¾“å‡ºç›®å½•\n",
        "            save_crops: æ˜¯å¦ä¿å­˜è£å‰ªå›¾åƒ\n",
        "        \"\"\"\n",
        "        image_dir = Path(image_dir)\n",
        "        output_dir = Path(output_dir)\n",
        "        output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        vis_dir = output_dir / 'visualizations'\n",
        "        vis_dir.mkdir(exist_ok=True)\n",
        "\n",
        "        crops_dir = output_dir / 'crops' if save_crops else None\n",
        "        if crops_dir:\n",
        "            for class_name in self.class_names:\n",
        "                (crops_dir / class_name).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # è·å–æ‰€æœ‰å›¾åƒ\n",
        "        image_paths = list(image_dir.glob('*.jpg')) + list(image_dir.glob('*.png'))\n",
        "\n",
        "        all_results = {}\n",
        "        stats = {'Long': 0, 'Short': 0}\n",
        "\n",
        "        print(f\"\\nå¤„ç† {len(image_paths)} å¼ å›¾åƒ...\")\n",
        "        for img_path in tqdm(image_paths):\n",
        "            save_path = vis_dir / img_path.name\n",
        "            results = self.process_image(img_path, save_path, save_crops, crops_dir)\n",
        "\n",
        "            all_results[img_path.name] = results\n",
        "\n",
        "            # ç»Ÿè®¡\n",
        "            for result in results:\n",
        "                stats[result['class']] += 1\n",
        "\n",
        "        # ä¿å­˜ç»“æœ\n",
        "        with open(output_dir / 'results.json', 'w', encoding='utf-8') as f:\n",
        "            json.dump(all_results, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯\n",
        "        print(f\"\\nâœ… å¤„ç†å®Œæˆï¼\")\n",
        "        print(f\"ç»“æœä¿å­˜åœ¨: {output_dir}\")\n",
        "        print(f\"\\nç»Ÿè®¡ä¿¡æ¯:\")\n",
        "        total = sum(stats.values())\n",
        "        for class_name, count in stats.items():\n",
        "            percentage = 100 * count / total if total > 0 else 0\n",
        "            print(f\"  {class_name}: {count} ({percentage:.1f}%)\")\n",
        "\n",
        "        # ä¿å­˜ç»Ÿè®¡\n",
        "        with open(output_dir / 'statistics.json', 'w', encoding='utf-8') as f:\n",
        "            json.dump(stats, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        return all_results, stats\n",
        "\n",
        "    def visualize_results(self, image_path, results, save_path):\n",
        "        \"\"\"å¯è§†åŒ–æ£€æµ‹å’Œåˆ†ç±»ç»“æœ\"\"\"\n",
        "        # è¯»å–å›¾åƒ\n",
        "        image = cv2.imread(str(image_path))\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # ç»˜åˆ¶\n",
        "        fig, ax = plt.subplots(1, figsize=(12, 12))\n",
        "        ax.imshow(image)\n",
        "\n",
        "        colors = {'Long': 'green', 'Short': 'red'}\n",
        "\n",
        "        for result in results:\n",
        "            x1, y1, x2, y2 = result['box']\n",
        "            class_name = result['class']\n",
        "            det_conf = result['det_conf']\n",
        "            cls_conf = result['cls_conf']\n",
        "\n",
        "            color = colors.get(class_name, 'blue')\n",
        "\n",
        "            # ç»˜åˆ¶æ£€æµ‹æ¡†\n",
        "            rect = patches.Rectangle((x1, y1), x2-x1, y2-y1,\n",
        "                                     linewidth=2, edgecolor=color, facecolor='none')\n",
        "            ax.add_patch(rect)\n",
        "\n",
        "            # æ·»åŠ æ ‡ç­¾\n",
        "            label = f\"{class_name} {cls_conf:.2f}\"\n",
        "            ax.text(x1, y1-10, label, color='white', fontsize=10,\n",
        "                   bbox=dict(facecolor=color, alpha=0.7, edgecolor='none', pad=2))\n",
        "\n",
        "        ax.axis('off')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "\n",
        "def main():\n",
        "    # é…ç½®è·¯å¾„\n",
        "    detection_model_path = \"runs/detect/fly_detector/weights/best.pt\"\n",
        "    classification_model_path = \"runs/classification/best_model.pth\"\n",
        "\n",
        "    # åˆ›å»ºæ¨ç†æµç¨‹\n",
        "    pipeline = FlyDetectionClassificationPipeline(\n",
        "        detection_model_path=detection_model_path,\n",
        "        classification_model_path=classification_model_path,\n",
        "        classification_model_name='resnet50',\n",
        "        num_classes=2,\n",
        "        conf_threshold=0.25\n",
        "    )\n",
        "\n",
        "    # é€‰æ‹©å¤„ç†æ¨¡å¼\n",
        "    import sys\n",
        "    if len(sys.argv) > 1:\n",
        "        mode = sys.argv[1]\n",
        "    else:\n",
        "        mode = 'batch'  # é»˜è®¤æ‰¹é‡å¤„ç†\n",
        "\n",
        "    if mode == 'single':\n",
        "        # å•å¼ å›¾åƒæµ‹è¯•\n",
        "        if len(sys.argv) > 2:\n",
        "            image_path = sys.argv[2]\n",
        "        else:\n",
        "            image_path = \"data/flys/MVIMG_20251202_153157.jpg\"\n",
        "\n",
        "        output_path = \"test_output.jpg\"\n",
        "        results = pipeline.process_image(image_path, save_path=output_path,\n",
        "                                        save_crops=True, crops_dir='test_crops')\n",
        "\n",
        "        print(f\"\\næ£€æµ‹åˆ° {len(results)} åªæœè‡:\")\n",
        "        for i, result in enumerate(results, 1):\n",
        "            print(f\"  {i}. {result['class']} (åˆ†ç±»ç½®ä¿¡åº¦: {result['cls_conf']:.3f}, \"\n",
        "                  f\"æ£€æµ‹ç½®ä¿¡åº¦: {result['det_conf']:.3f})\")\n",
        "\n",
        "    else:\n",
        "        # æ‰¹é‡å¤„ç†\n",
        "        if len(sys.argv) > 2:\n",
        "            image_dir = sys.argv[2]\n",
        "        else:\n",
        "            image_dir = \"processed_data/detection/val/images\"\n",
        "\n",
        "        output_dir = \"inference_results\"\n",
        "\n",
        "        all_results, stats = pipeline.process_batch(\n",
        "            image_dir=image_dir,\n",
        "            output_dir=output_dir,\n",
        "            save_crops=True\n",
        "        )\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}